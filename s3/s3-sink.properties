# Kafka S3 sink example
# See comments for different examples such as multiple topics
# and different output formats and partitioners

name=s3-sink
connector.class=io.confluent.connect.s3.S3SinkConnector
tasks.max=1

# One or more topics?
topics=mysql-employees
# topics.regex=mysql*

s3.region=us-east-1
s3.bucket.name=kafka-connect-example
s3.part.size=5242880
flush.size=3

storage.class=io.confluent.connect.s3.storage.S3Storage

#Output to Avro,Parquet or JSON?
format.class=io.confluent.connect.s3.format.avro.AvroFormat
#format.class=io.confluent.connect.s3.format.parquet.ParquetFormat
#format.class=io.confluent.connect.s3.format.json.JsonFormat

partitioner.class=io.confluent.connect.storage.partitioner.DefaultPartitioner
#partitioner.class= io.confluent.connect.storage.partitioner.DailyPartitioner
# https://docs.confluent.io/current/connect/kafka-connect-s3/index.html#partitioning-records-into-s3-objects for more on partitioning options

schema.compatibility=NONE
#partition.field.name=
#partition.duration.ms=
#path.format=
#locale=
#timezone=
